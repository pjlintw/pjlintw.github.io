---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- I am a first-year PhD student, advised by [Tu Vu](https://tuvllms.github.io/) at [Virginia Tech](https://cs.vt.edu/). My research aims to develop efficient artificial intelligent (AI) models for communal and collaborative generalization. How can we teach AI model a suite of skills efficiently? Specifically, I have worked on improving model adaptation, measuring the effects of data and prompts, and addressing data scarcity through synthetic data. I am now exploring representative skill combinations. -->

I'm a CS Ph.D. student at the Large Language Models (LLMs) Lab at [Virginia Tech](https://cs.vt.edu/). My research aims to develop efficient artificial intelligence (AI) models for communal and collaborative generalization, with a focus on facilitating the development of machine learning models more efficiently and effectively. My work explores sample-efficient methods to learn a unified model that combines multiple skills‚Äîsuch as safety, math, coding, and multilingual capabilities.

I'm advised by [Tu Vu](https://tuvllms.github.io/). Previously, I received the Master's at the [Language Science and Technology Department (LST)](https://www.uni-saarland.de/en/department/lst/research.html) of Saarland University, where I worked with [Dietrich Klakow](https://www.lsv.uni-saarland.de/people/dietrich-klakow/) and [Vera Demberg](https://www.uni-saarland.de/lehrstuhl/demberg/members/verademberg.html). Prior to that, I contributed to the development of NLP system for historical archives with [Richard Tsai](https://scholar.google.com.tw/citations?user=iDz3gJ4AAAAJ&hl=zh-TW) and [Liu Yuan-ju](https://www.harvard-yenching.org/person/liu-yuan-ju/) at [Academia Sinica](https://www.sinica.edu.tw/en). I obtained my Bachelor‚Äôs in History.


### Research

My research interests broadly revolve around efficient NLP which span a wide range of captivating topics including:

- Efficient transfer learning: [In-Context Prompt Editing](https://arxiv.org/abs/2311.00895), [Open Prompt Alignment](https://arxiv.org/abs/2311.00897), [Sample Size Determination](https://aclanthology.org/2023.findings-acl.419/), [LED](https://aclanthology.org/2022.creativesumm-1.9/).
- NLP for low-resource languages: [CaT](https://arxiv.org/abs/2307.00382).


<!-- - Semantic space for task information encoding: [IIT](https://drive.google.com/file/d/1cRGYOvBls695iaOWhuV_8bJoIKy1EUMy/view?usp=sharing). -->

<!-- These days, I‚Äôm excited about delving into the behavior of LMs ‚Äî understanding how they learn and process information at different levels. Pertinent sub- questions arise, such as understanding the specific information transmitted through within-tuning phases and cross-tuning phases. Furthermore, exploring how LMs store information in their knowledge reservoirs and how they can selectively purge or forget knowledge from this reservoir.
-->

Email: pinjie(at)vt.edu

<!-- <span style="color:darkgreen"> -->
<!-- I am actively seeking a internship/student research for Winter 2024. I invite you to review my CV for further details. [CV](https://drive.google.com/file/d/1OHTYGY6oKKbaG0BDucPI__Ij4LYmRm4y/view?usp=sharing).</span> -->

<!-- <br /> -->


# üî• News

- *2024.09*: 1 paper *Target-Aware Language Modeling via Granular Data Sampling* got accepted to EMNLP 2024.
- *2024.08*: I started my PhD study at Virginia Tech.
- *2024.07*: 1 paper *Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning: A Systematic Study* got accepted to ACL 2024 Student Research Workshop!
- *2024.03*: I will spend time in Taipei in March and April. Feel free to reach out if you‚Äôre in the area and would like to meet up! 
- *2024.02*: I successfully presented my Master thesis *Exploring Task Selection for Intermediate-Task Transfer Learning*.
- *2024.02*: 1 paper *Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin* acceted at LREC-COLING 2024.
- *2024.01*: 1 paper *Projecting Annotations for Discourse Relations: Connective Identification for Low Resource Languages* accepted to the Workshop on Computational Approaches to Discourse at EACL 2023.

<!-- - *2023.12*: üéâüòä Our paper *In-Context Prompt Editing For Conditional Audio Generation* has been accepted at ICASSP 2024.
- *2023.12*: The paper *On the Open Prompt Challenge in Conditional Audio Generation* has been accepted at ICASSP 2024.
- *2023.09*: I have been selected for the 2023B cohort of Google's CS Research Mentorship Program (CSRMP).
- *2023.05*: üéâü•∞ Our new paper *Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin* has been accepted at Interspeech 2023.
- *2023.05*: üéâüéâ Our new paper has been accepted at ACL 2023 findings. 

- *2022.10*: üéâüéâ Our new paper *[Two-Stage Movie Script Summarization: An Efficient Method For Low-Resource Long Document Summarization
](https://aclanthology.org/2022.creativesumm-1.9)* will be presented at the workshop on Automatic Summarization for Creative Writing at COLING 2022. Our system ranks **1st** in the Script-base track.
- *2022.04*: I will present our software project for short story recommendations (with Niyati Bafna) at Saarland university. 

- *2020.10*: I start my journey at Saarland university.

- *2019.12*: Our paper will be presented at conference DADH 2019. 
- *2019.08*: I will give a talk about *Climate Event system based on Historical Meteorological Records* at National Central University.
- *2019.08*: I gave a tutorial for [Hello, Sequence Labeling](https://docs.google.com/presentation/d/1jdZOhs8woyt4G0nYonhlUoFmsCGW_udfGYcsA3--Axw/edit?usp=sharing) in the Summer Program at National Central University.

- *2018.12*: Our paper will be presented at conference DADH 2018. 
- *2018.07*: I gave a invited talk about Python programming on Digital Humanities Workshop at National Taiwan University. -->

<br /> 

# üìù <a id="-Publications">Selected Publications</a>

Please see [Google Scholar](https://scholar.google.com/citations?user=KYeOpSoAAAAJ&hl=en&authuser=1) for an up-to-date publication list.

\* indicates equal contributions

<!--
**Exploring Task Selection for Intermediate-Task Transfer Learning** <br />
 **<ins>Pin-Jie Lin</ins>** <br /> 
Master's thesis <br />
[\[Paper\]](https://drive.google.com/file/d/1-5P8GKM2BTDTPQoAfXyS4UzDYeAhAZvy/view?usp=sharing) [\[Slide\]](https://drive.google.com/file/d/1hWJdDhLGZk0CN5QP4EZlBY-sOzmHkbmd/view?usp=sharing) <br />
-->

<!-- **Target-Aware Language Modeling via Granular Data Sampling** <br />
**<ins>Pin-Jie Lin</ins>**, Miaoran Zhang, Marius Mosbach, Dietrich Klakow<br />
Student Research Workshop at ACL 2024 <br />
[\[Paper\]](https://aclanthology.org/2024.acl-srw.24/) [\[Code\]](https://github.com/uds-lsv/intermediate-task-selection/) <br />
// We revist the task -->

**Target-Aware Language Modeling via Granular Data Sampling** <br />
Ernie Chang, **<ins>Pin-Jie Lin</ins>**, Yang Li, Changsheng Zhao, Daeil Kim, Rastislav Rabtin, Zechun Liu, Yangyang Shi,, Vikas Chandra <br /> 
EMNLP 2024 <br />

**Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning** <br />
**<ins>Pin-Jie Lin</ins>**, Miaoran Zhang, Marius Mosbach, Dietrich Klakow<br />
Student Research Workshop at ACL 2024 <br />
[\[Paper\]](https://aclanthology.org/2024.acl-srw.24/) [\[Code\]](https://github.com/uds-lsv/intermediate-task-selection/) <br />


**Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning** <br />
**<ins>Pin-Jie Lin</ins>**, Miaoran Zhang, Marius Mosbach, Dietrich Klakow<br />
Student Research Workshop at ACL 2024 <br />
[\[Paper\]](https://aclanthology.org/2024.acl-srw.24/) [\[Code\]](https://github.com/uds-lsv/intermediate-task-selection/)<br />


**Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin** <br />
**<ins>Pin-Jie Lin</ins>**, Merel Scholman, Muhammed Saeed, Vera Demberg <br />
LREC-COLING 2024 <br />
[\[Paper\]](https://aclanthology.org/2024.lrec-main.1006/) <br />


<!-- **Projecting Annotations for Discourse Relations: Connective Identification for Low Resource Languages** <br />
Peter Bourgonje, **<ins>Pin-Jie Lin</ins>** <br />
Workshop on Computational Approaches to Discourse at EACL 2024 <br />
[\[Paper\]](https://aclanthology.org/2024.codi-1.4/) <br />
 -->

**In-Context Prompt Editing For Conditional Audio Generation** <br />
Ernie Chang\*, **<ins>Pin-Jie Lin</ins>\***, Yang Li, Sidd Srinivasan, Gael Le Lan, David Kant, Yangyang Shi, Forrest Iandola, Vikas Chandra <br /> 
ICASSP 2024 <br />
[\[Paper\]](https://ieeexplore.ieee.org/document/10446431) <br />
<span style="color:purple">HuggingFace Daily Paper and twelve picks by Jordi Pons</span>


<!-- **On the Open Prompt Challenge in Conditional Audio Generation** <br />
Ernie Chang, Sidd Srinivasan, Mahi Luthra, **<ins>Pin-Jie Lin</ins>**, Varun K. Nagaraja, Forrest Iandola, Zechun Liu, Zhaoheng Ni, Changsheng Zhao, Yangyang Shi, Vikas Chandra <br />
ICASSP 2024 <br /> -->

**Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin** <br />
**<ins>Pin-Jie Lin</ins>\***, Muhammed Saeed\*, Ernie Chang\*, Merel Scholman <br /> 
Interspeech 2023 <br />
[\[Paper\]](https://www.isca-archive.org/interspeech_2023/lin23e_interspeech.html) <br />
<span style="color:purple">We address one of the most underrepresented low-resource languages in the world. Our benchmark is publicly available</span>

**Revisiting Sample Size Determination in Natural Language Understanding** <br />
Ernie Chang\*, Muhammad Hassan Rashid\*, **<ins>Pin-Jie Lin</ins>\***, Changsheng Zhao, Vera Demberg, Yangyang Shi and Vikas Chandra <br />
ACL 2023 Findings <br />
[\[Paper\]](https://aclanthology.org/2023.findings-acl.419/) <br />
<span style="color:purple">Our approach forecasts model performance with 0.9% error, using only 10% of the data</span>


**Two-Stage Movie Script Summarization: An Efficient Method For Low-Resource Long Document Summarization** <br />
Dongqi Pu\*, Xudong Hong\*, **<ins>Pin-Jie Lin</ins>\***, Ernie Chang, Vera Demberg <br />
COLING 2022 <br />
[\[Paper\]](https://aclanthology.org/2022.creativesumm-1.9/) <br />
<span style="color:purple">The top-performaing movie script summarizer</span>

<!--
**Event Extraction: Convolutional Neural Networks for Extracting Medieval
Chinese Monk‚Äôs Travels**  <br />
**<ins>Pin-Jie Lin</ins>**, Bing-Lin Tsai <br />
International Conference of Digital Archives and Digital Humanities 2019 <br />

**Name Recognition of Medieval Chinese
Monk Names** <br />
Severina Balabanova, **<ins>Pin-Jie Lin</ins>**, Ya-Lin Chen, Wan-Chun Chiu <br />
International Conference of Digital Archives and Digital Humanities 2018 <br />
 -->

