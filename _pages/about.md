---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I am a master's student at the [Language Science and Technology Department (LST)](https://www.uni-saarland.de/en/department/lst/research.html) of Saarland University, where I work with [Dietriech Klakow](https://www.lsv.uni-saarland.de/people/dietrich-klakow/) and [Vera Demberg](https://www.uni-saarland.de/lehrstuhl/demberg/members/verademberg.html). 

Prior to that, I worked with [Richard Tzong-Han Tsai](https://www.iisr.csie.ncu.edu.tw/faculty) at Intelligent Information Service Research Lab (IISR) and [Liu Yuan-ju](https://www.litphil.sinica.edu.tw/people/researchers/Liu,%20Yuan-ju) at Academia Sinica, Taiwan. 

My primary research interests broadly revolve around efficient NLP which span a wide range of captivating topics including:

- Efficient transfer learning: [In-Context Prompt Editing](https://arxiv.org/abs/2311.00895), [Open Prompt Alignment](https://arxiv.org/abs/2311.00897), [Sample Size Determination](https://aclanthology.org/2023.findings-acl.419/), [LED](https://aclanthology.org/2022.creativesumm-1.9/).
- NLP for low-resource languages: [CaT](https://arxiv.org/abs/2307.00382).
- Semantic space for task information encoding: [IIT](https://drive.google.com/file/d/1cRGYOvBls695iaOWhuV_8bJoIKy1EUMy/view?usp=sharing).

These days, I‚Äôm excited about delving into the behavior of LMs ‚Äî understanding how they learn and process information at different levels. Pertinent sub-questions arise, such as understanding the specific information transmitted through within-tuning phases and cross-tuning phases. Furthermore, exploring how LMs store information in their knowledge reservoirs and how they can selectively purge or forget knowledge from this reservoir.

Email: pinjie [at] lst.uni-saarland.de

<span style="color:darkgreen">
I am interested in enrolling in a Ph.D. program for Fall 2024 and am actively seeking a internship/student research for Winter 2024. I invite you to review my CV for further details. [CV](https://drive.google.com/file/d/188MU4WOr1RBt9UZM7h_7h8KwzDlYGD7j/view?usp=sharing).</span>

<br />

# üî• News
- *2024.02*: I successfully presented my Master thesis.
- *2024.02*: 1 paper acceted at LREC-COLING 2024.
- *2024.01*: 1 paper accepted at EACL 2023.

- *2023.12*: üòä One paper In-Context Prompt Editing For Conditional Audio Generation has been accepted at ICASSP 2024.
- *2023.12*: One paper On the Open Prompt Challenge in Conditional Audio Generation has been accepted at ICASSP 2024.
- *2023.09*: I have been selected for the 2023B cohort of Google's CS Research Mentorship Program (CSRMP).
- *2023.05*: üéâü•∞ Our new paper Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin has been accepted at Interspeech 2023.
- *2023.05*: üéâüéâ Our new paper has been accepted at ACL 2023 findings. 

- *2022.10*: üéâüéâ Our new paper [Two-Stage Movie Script Summarization: An Efficient Method For Low-Resource Long Document Summarization
](https://aclanthology.org/2022.creativesumm-1.9) will be presented at the workshop on Automatic Summarization for Creative Writing at COLING 2022. Our system ranks **1st** in the Script-base track.
- *2022.04*: I will present our software project for short story recommendations (with Niyati Bafna) at Saarland university. 

- *2020.10*: I start my journey at Saarland university.

- *2019.12*: Our paper will be presented at conference DADH 2019. 
- *2019.08*: I will give a talk about Climate Event system based on Historical Meteorological Records at National Central University.
- *2019.08*: I gave a tutorial for [Hello, Sequence Labeling](https://docs.google.com/presentation/d/1jdZOhs8woyt4G0nYonhlUoFmsCGW_udfGYcsA3--Axw/edit?usp=sharing) in the Summer Program at National Central University.

- *2018.12*: Our paper will be presented at conference DADH 2018. 
- *2018.07*: I gave a invited talk about Python programming on Digital Humanities Workshop at National Taiwan University.

<br />

# üìù <a id="-Publications">Publications</a>

\* indicates equal contributions

**Exploring Task Selection for Intermediate-Task Transfer Learning** <br />
 **<ins>Pin-Jie Lin</ins>** <br /> 
Master's thesis <br />
[\[Paper\]](https://drive.google.com/file/d/1-5P8GKM2BTDTPQoAfXyS4UzDYeAhAZvy/view?usp=sharing) [\[Slide\]](https://drive.google.com/file/d/1wgnuGcDAEW26xpEhf6tnltXY97zwXi95/view?usp=sharing) <br />

**Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin** <br />
**<ins>Pin-Jie Lin</ins>**, Merel Scholman, Muhammed Saeed, Vera Demberg <br />
LREC-COLING 2024 <br />

**Projecting Annotations for Discourse Relations: Connective Identification for Low Resource Languages** <br />
Peter Bourgonje, **<ins>Pin-Jie Lin</ins>** <br />
To Appear at Workshop on Computational Approaches to Discourse at EACL 2024 <br />

**In-Context Prompt Editing For Conditional Audio Generation** <br />
Ernie Chang\*, **<ins>Pin-Jie Lin</ins>\***, Yang Li, Sidd Srinivasan, Gael Le Lan, David Kant, Yangyang Shi, Forrest Iandola, Vikas Chandra <br /> 
ICASSP 2024 <br />

**On the Open Prompt Challenge in Conditional Audio Generation** <br />
Ernie Chang, Sidd Srinivasan, Mahi Luthra, **<ins>Pin-Jie Lin</ins>**, Varun K. Nagaraja, Forrest Iandola, Zechun Liu, Zhaoheng Ni, Changsheng Zhao, Yangyang Shi, Vikas Chandra <br />
ICASSP 2024 <br />

**Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin** <br />
**<ins>Pin-Jie Lin</ins>\***, Muhammed Saeed\*, Ernie Chang\*, Merel Scholman <br /> 
Interspeech 2023 <br />
[\[Paper\]](https://arxiv.org/abs/2307.00382) <br />

**Revisiting Sample Size Determination in Natural Language Understanding** <br />
Ernie Chang\*, Muhammad Hassan Rashid\*, **<ins>Pin-Jie Lin</ins>\***, Changsheng Zhao, Vera Demberg, Yangyang Shi and Vikas Chandra <br />
ACL 2023 Findings <br />
[\[Paper\]](https://arxiv.org/abs/2307.00374) <br />

**Two-Stage Movie Script Summarization: An Efficient Method For Low-Resource Long Document Summarization** <br />
Dongqi Pu\*, Xudong Hong\*, **<ins>Pin-Jie Lin</ins>\***, Ernie Chang, Vera Demberg <br />
COLING 2022 <br />
[\[Paper\]](https://aclanthology.org/2022.creativesumm-1.9/) <br />

**Event Extraction: Convolutional Neural Networks for Extracting Medieval
Chinese Monk‚Äôs Travels**  <br />
**<ins>Pin-Jie Lin</ins>**, Bing-Lin Hsieh  <br />
International Conference of Digital Archives and Digital Humanitie 2019 <br />

**Name Recognition of Medieval Chinese
Monk Names** <br />
Severina Balabanova, **<ins>Pin-Jie Lin</ins>**, Ya-Lin Chen, Wan-Chun Chiu <br />
International Conference of Digital Archives and Digital Humanities 2018 <br />


