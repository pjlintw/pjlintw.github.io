---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- I am a first-year PhD student, advised by [Tu Vu](https://tuvllms.github.io/) at [Virginia Tech](https://cs.vt.edu/). My research aims to develop efficient artificial intelligent (AI) models for communal and collaborative generalization. How can we teach AI model a suite of skills efficiently? Specifically, I have worked on improving model adaptation, measuring the effects of data and prompts, and addressing data scarcity through synthetic data. I am now exploring representative skill combinations. -->

I'm a CS Ph.D. student at [Virginia Tech](https://cs.vt.edu/)'s Large Language Models (LLMs) Lab. My research focuses on **collaborative and communal machine learning**, aiming to efficiently and effectively develop an all-rounded LLMs. I explore methods that blend a diverse set of skills, including safety, tool use, coding, multilingual and instruction-following capabilities. These methods encompass model merging, modular composition, and model adaptation.


I'm advised by [Tu Vu](https://tuvllms.github.io/). Previously, I received the Master's at the [Language Science and Technology Department (LST)](https://www.uni-saarland.de/en/department/lst/research.html) of Saarland University, where I worked with [Dietrich Klakow](https://www.lsv.uni-saarland.de/people/dietrich-klakow/) and [Vera Demberg](https://www.uni-saarland.de/lehrstuhl/demberg/members/verademberg.html). Prior to that, I contributed to the development of NLP system for historical archives with [Richard Tsai](https://scholar.google.com.tw/citations?user=iDz3gJ4AAAAJ&hl=zh-TW) and [Liu Yuan-ju](https://www.harvard-yenching.org/person/liu-yuan-ju/) at [Academia Sinica](https://www.sinica.edu.tw/en). I obtained my Bachelor‚Äôs in History.


### Research

My research broadly revolve around efficient NLP which span a wide range of captivating topics including:

- Efficient transfer learning: transferring knowledge across tasks, and modalities
([Intermediate-task Transfer Learning](https://aclanthology.org/2024.acl-srw.24/), [In-Context Prompt Editing](https://arxiv.org/abs/2311.00895)).


- NLP for low-resource languages: enhancing NLP models' capacity for underrepresented languages ([CaT](https://arxiv.org/abs/2307.00382)).

- Sample selection: optimizing LLMs' performance through effective data mixtures ([Target-aware Language Modeling](https://arxiv.org/abs/2409.14705/), [Sample Size Determination](https://aclanthology.org/2023.findings-acl.419/)).


<!-- - Semantic space for task information encoding: [IIT](https://drive.google.com/file/d/1cRGYOvBls695iaOWhuV_8bJoIKy1EUMy/view?usp=sharing). -->

<!-- These days, I‚Äôm excited about delving into the behavior of LMs ‚Äî understanding how they learn and process information at different levels. Pertinent sub- questions arise, such as understanding the specific information transmitted through within-tuning phases and cross-tuning phases. Furthermore, exploring how LMs store information in their knowledge reservoirs and how they can selectively purge or forget knowledge from this reservoir.
-->

Email: pinjie(at)vt.edu

<!-- <span style="color:darkgreen"> -->
<!-- I am actively seeking a internship/student research for Winter 2024. I invite you to review my CV for further details. [CV](https://drive.google.com/file/d/1OHTYGY6oKKbaG0BDucPI__Ij4LYmRm4y/view?usp=sharing).</span> -->

<!-- <br /> -->


# üî• News

- *2024.10*: 1 paper got accepted to EMNLP 2024 Industry Track.
- *2024.09*: 1 paper *Target-Aware Language Modeling via Granular Data Sampling* got accepted to EMNLP 2024.
- *2024.08*: I started my PhD study at Virginia Tech.
- *2024.07*: 1 paper *Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning: A Systematic Study* got accepted to ACL 2024 Student Research Workshop!
- *2024.03*: I will spend time in Taipei in March and April. Feel free to reach out if you‚Äôre in the area and would like to meet up! 
- *2024.02*: I successfully presented my Master thesis *Exploring Task Selection for Intermediate-Task Transfer Learning*.
- *2024.02*: 1 paper *Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin* acceted at LREC-COLING 2024.
- *2024.01*: 1 paper *Projecting Annotations for Discourse Relations: Connective Identification for Low Resource Languages* accepted to the Workshop on Computational Approaches to Discourse at EACL 2023.

<!-- - *2023.12*: üéâüòä Our paper *In-Context Prompt Editing For Conditional Audio Generation* has been accepted at ICASSP 2024.
- *2023.12*: The paper *On the Open Prompt Challenge in Conditional Audio Generation* has been accepted at ICASSP 2024.
- *2023.09*: I have been selected for the 2023B cohort of Google's CS Research Mentorship Program (CSRMP).
- *2023.05*: üéâü•∞ Our new paper *Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin* has been accepted at Interspeech 2023.
- *2023.05*: üéâüéâ Our new paper has been accepted at ACL 2023 findings. 

- *2022.10*: üéâüéâ Our new paper *[Two-Stage Movie Script Summarization: An Efficient Method For Low-Resource Long Document Summarization
](https://aclanthology.org/2022.creativesumm-1.9)* will be presented at the workshop on Automatic Summarization for Creative Writing at COLING 2022. Our system ranks **1st** in the Script-base track.
- *2022.04*: I will present our software project for short story recommendations (with Niyati Bafna) at Saarland university. 

- *2020.10*: I start my journey at Saarland university.

- *2019.12*: Our paper will be presented at conference DADH 2019. 
- *2019.08*: I will give a talk about *Climate Event system based on Historical Meteorological Records* at National Central University.
- *2019.08*: I gave a tutorial for [Hello, Sequence Labeling](https://docs.google.com/presentation/d/1jdZOhs8woyt4G0nYonhlUoFmsCGW_udfGYcsA3--Axw/edit?usp=sharing) in the Summer Program at National Central University.

- *2018.12*: Our paper will be presented at conference DADH 2018. 
- *2018.07*: I gave a invited talk about Python programming on Digital Humanities Workshop at National Taiwan University. -->

<br /> 

# üìù <a id="-Publications">Selected Publications</a>


Please see [Google Scholar](https://scholar.google.com/citations?user=KYeOpSoAAAAJ&hl=en&authuser=1) for an up-to-date publication list.

\* indicates equal contributions


<style>
    :root {
        --img-width: 200px;
    }
    img {
        width: var(--img-width);
    }
</style>


<div style="display: flex; align-items: center;">
    <img src="imgs/sampling-img-5.jpg" alt="Description" style="width: {{ site.img_width }}; height: auto; margin-right: 20px; box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.5);">
    <div>
        <a href="https://arxiv.org/abs/2409.14705" style="color:teal;"><strong>Target-Aware Language Modeling via Granular Data Sampling</strong></a> <br />
        Ernie Chang, <strong><ins>Pin-Jie Lin</ins></strong>, Yang Li, Changsheng Zhao, Daeil Kim, Rastislav Rabtin, Zechun Liu, Yangyang Shi, Vikas Chandra <br />
        EMNLP 2024 <br />
        <a href="https://arxiv.org/abs/2409.14705" style="color:gray; text-decoration:none;">[Paper]</a> <br />
        <span style="color:purple">Using ~1% of RefinedWeb data, models match full pretraining performance</span>
    </div>
</div>
<br />

<div style="display: flex; align-items: center;">
    <img src="images/imgs/task-emb-img-1.jpg" alt="Description" style="width: {{ site.img_width }}; height: auto; margin-right: 20px; box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.5);">
    <div>
        <a href="https://aclanthology.org/2024.acl-srw.24/" style="color:teal;"><strong>Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning</strong></a> <br />
        <strong><ins>Pin-Jie Lin</ins></strong>, Miaoran Zhang, Marius Mosbach, Dietrich Klakow <br />
        Student Research Workshop at ACL 2024 <br />
        <a href="https://aclanthology.org/2024.acl-srw.24/" style="color:gray; text-decoration:none;">[Paper]</a> <a href="https://github.com/uds-lsv/intermediate-task-selection/" style="color:gray; text-decoration:none;">[Code]</a><br />
    </div>
</div>
<br />

<div style="display: flex; align-items: center;">
    <img src="images/imgs/ov-img-4.jpg" alt="Description" style="width: {{ site.img_width }}; height: auto; margin-right: 20px; box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.5);">
    <div>
        <a href="https://aclanthology.org/2024.lrec-main.1006/" style="color:teal;"><strong>Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin</strong></a> <br />
        <strong><ins>Pin-Jie Lin</ins></strong>, Merel Scholman, Muhammed Saeed, Vera Demberg <br />
        LREC-COLING 2024 <br />
        <a href="https://aclanthology.org/2024.lrec-main.1006/" style="color:gray; text-decoration:none;">[Paper]</a> <br />
        <span style="color:purple">Our synthetic data are generated from a phonological-theoretic, parameter-free framework</span>
    </div>
</div>
<br />

<div style="display: flex; align-items: center;">
    <img src="images/imgs/in-context-img-1.jpg" alt="Description" style="width: {{ site.img_width }}; height: auto; margin-right: 20px; box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.5);">
    <div>
        <a href="https://ieeexplore.ieee.org/document/10446431" style="color:teal;"><strong>In-Context Prompt Editing For Conditional Audio Generation</strong></a> <br />
        Ernie Chang*, <strong><ins>Pin-Jie Lin</ins>*</strong>, Yang Li, Sidd Srinivasan, Gael Le Lan, David Kant, Yangyang Shi, Forrest Iandola, Vikas Chandra <br />
        ICASSP 2024 <br />
        <a href="https://ieeexplore.ieee.org/document/10446431" style="color:gray; text-decoration:none;">[Paper]</a> <br />
        <span style="color:purple">HuggingFace Daily Paper and twelve picks by Jordi Pons</span>
    </div>
</div>
<br />


<!-- **On the Open Prompt Challenge in Conditional Audio Generation** <br />
Ernie Chang, Sidd Srinivasan, Mahi Luthra, **<ins>Pin-Jie Lin</ins>**, Varun K. Nagaraja, Forrest Iandola, Zechun Liu, Zhaoheng Ni, Changsheng Zhao, Yangyang Shi, Vikas Chandra <br />
ICASSP 2024 <br /> -->



<div style="display: flex; align-items: center;">
    <img src="images/imgs/cat-img-3.jpg" alt="Description" style="width: {{ site.img_width }}; height: auto; margin-right: 20px; box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.5);">
    <div>
        <a href="https://www.isca-archive.org/interspeech_2023/lin23e_interspeech.html" style="color:teal;"><strong>Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin</strong></a> <br />
        <strong><ins>Pin-Jie Lin</ins>*</strong>, Muhammed Saeed*, Ernie Chang*, Merel Scholman <br />
        Interspeech 2023 <br />
        <a href="https://www.isca-archive.org/interspeech_2023/lin23e_interspeech.html" style="color:gray; text-decoration:none;">[Paper]</a> <br />
        <span style="color:purple">We address one of the most underrepresented low-resource languages in the world. Our benchmark is publicly available</span>
    </div>
</div>
<br />


<div style="display: flex; align-items: center;">
    <img src="images/imgs/sample-size-img-1.jpg" alt="Description" style="width: {{ site.img_width }}; height: auto; margin-right: 20px; box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.5);">
    <div>
        <a href="https://aclanthology.org/2023.findings-acl.419/" style="color:teal;"><strong>Revisiting Sample Size Determination in Natural Language Understanding</strong></a> <br />
        Ernie Chang*, Muhammad Hassan Rashid*, <strong><ins>Pin-Jie Lin</ins>*</strong>, Changsheng Zhao, Vera Demberg, Yangyang Shi and Vikas Chandra <br />
        ACL 2023 Findings <br />
        <a href="https://aclanthology.org/2023.findings-acl.419/" style="color:gray; text-decoration:none;">[Paper]</a> <a href="https://github.com/pjlintw/sample-size" style="color:gray; text-decoration:none;">[Code]</a>
        <br />
        <span style="color:purple">Our approach forecasts model performance with 0.9% error, using only 10% of the data</span>
    </div>
</div>
<br />

<div style="display: flex; align-items: center;">
    <img src="images/imgs/sum-img-1.jpg" alt="Description" style="width: {{ site.img_width }}; height: auto; margin-right: 20px; box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.5);">
    <div>
        <a href="https://aclanthology.org/2022.creativesumm-1.9/" style="color:teal;"><strong>Two-Stage Movie Script Summarization: An Efficient Method For Low-Resource Long Document Summarization</strong></a> <br />
        Dongqi Pu*, Xudong Hong*, <strong><ins>Pin-Jie Lin</ins>*</strong>, Ernie Chang, Vera Demberg <br />
        COLING 2022 <br />
        <a href="https://aclanthology.org/2022.creativesumm-1.9/" style="color:gray; text-decoration:none;">[Paper]</a> <br />
        <span style="color:purple">The top-performing movie script summarizer</span>
    </div>
</div>



<!--
**Event Extraction: Convolutional Neural Networks for Extracting Medieval
Chinese Monk‚Äôs Travels**  <br />
**<ins>Pin-Jie Lin</ins>**, Bing-Lin Tsai <br />
International Conference of Digital Archives and Digital Humanities 2019 <br />

**Name Recognition of Medieval Chinese
Monk Names** <br />
Severina Balabanova, **<ins>Pin-Jie Lin</ins>**, Ya-Lin Chen, Wan-Chun Chiu <br />
International Conference of Digital Archives and Digital Humanities 2018 <br />
 -->